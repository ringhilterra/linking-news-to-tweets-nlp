{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will read in all the cleaned tweet .csv files provided and write them to postgres tables, (1 per file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it assumes you have unzipped the ProcessedTweetDataFeb file in this directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlalchemy as sq\n",
    "import io\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_rows\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PG_CONN_STRING = 'postgresql://ubuntu:admin@10.60.97.4:5432/postgres'\n",
    "engine = sq.create_engine(PG_CONN_STRING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results_pg(result_df, tweet_table):\n",
    "    schema = 'ryan_test'\n",
    "    result_df.head(0).to_sql(tweet_table, con=engine, schema=schema, index=False, if_exists='replace') #truncates the table\n",
    "    conn = engine.raw_connection()\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SET search_path TO '{schema}'\".format(schema=schema))\n",
    "    output = io.StringIO()\n",
    "    result_df.to_csv(output, sep='\\t', header=False, index=False)\n",
    "    output.seek(0)\n",
    "    contents = output.getvalue()\n",
    "    cur.copy_from(output, table=tweet_table, null=\"\") # null values become ''\n",
    "    conn.commit()\n",
    "    print('completed write to table: {0}'.format(tweet_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through the tweet file directory and get all the file paths\n",
    "file_list = []\n",
    "day_dirs = os.listdir('ProcessedTweetDataMar/')\n",
    "for day_dir in day_dirs:\n",
    "    #print(day_dir)\n",
    "    if day_dir[0] != '.':\n",
    "        fnames = os.listdir('ProcessedTweetDataMar/'+day_dir)\n",
    "        fnames = [('ProcessedTweetDataMar/' + day_dir + '/' + x) for x in fnames]\n",
    "        file_list = file_list + fnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed write to table: tweetsprocessed2018_03_01_1\n",
      "completed write to table: tweetsprocessed2018_03_01_10\n",
      "completed write to table: tweetsprocessed2018_03_01_11\n",
      "completed write to table: tweetsprocessed2018_03_01_12\n",
      "completed write to table: tweetsprocessed2018_03_01_13\n",
      "completed write to table: tweetsprocessed2018_03_01_14\n",
      "completed write to table: tweetsprocessed2018_03_01_15\n",
      "completed write to table: tweetsprocessed2018_03_01_16\n",
      "completed write to table: tweetsprocessed2018_03_01_2\n",
      "completed write to table: tweetsprocessed2018_03_01_3\n",
      "completed write to table: tweetsprocessed2018_03_01_4\n",
      "completed write to table: tweetsprocessed2018_03_01_5\n",
      "completed write to table: tweetsprocessed2018_03_01_6\n",
      "completed write to table: tweetsprocessed2018_03_01_7\n",
      "completed write to table: tweetsprocessed2018_03_01_8\n",
      "completed write to table: tweetsprocessed2018_03_01_9\n",
      "completed write to table: tweetsprocessed2018_03_10_1\n",
      "completed write to table: tweetsprocessed2018_03_10_2\n",
      "completed write to table: tweetsprocessed2018_03_10_3\n",
      "completed write to table: tweetsprocessed2018_03_10_4\n",
      "completed write to table: tweetsprocessed2018_03_10_5\n",
      "completed write to table: tweetsprocessed2018_03_10_6\n",
      "completed write to table: tweetsprocessed2018_03_10_7\n",
      "completed write to table: tweetsprocessed2018_03_02_1\n",
      "completed write to table: tweetsprocessed2018_03_02_10\n",
      "completed write to table: tweetsprocessed2018_03_02_11\n",
      "completed write to table: tweetsprocessed2018_03_02_12\n",
      "completed write to table: tweetsprocessed2018_03_02_13\n",
      "completed write to table: tweetsprocessed2018_03_02_14\n",
      "completed write to table: tweetsprocessed2018_03_02_15\n",
      "completed write to table: tweetsprocessed2018_03_02_16\n",
      "completed write to table: tweetsprocessed2018_03_02_2\n",
      "completed write to table: tweetsprocessed2018_03_02_3\n",
      "completed write to table: tweetsprocessed2018_03_02_4\n",
      "completed write to table: tweetsprocessed2018_03_02_5\n",
      "completed write to table: tweetsprocessed2018_03_02_6\n",
      "completed write to table: tweetsprocessed2018_03_02_7\n",
      "completed write to table: tweetsprocessed2018_03_02_8\n",
      "completed write to table: tweetsprocessed2018_03_02_9\n",
      "completed write to table: tweetsprocessed2018_03_03_1\n",
      "completed write to table: tweetsprocessed2018_03_03_10\n",
      "completed write to table: tweetsprocessed2018_03_03_2\n",
      "completed write to table: tweetsprocessed2018_03_03_3\n",
      "completed write to table: tweetsprocessed2018_03_03_4\n",
      "completed write to table: tweetsprocessed2018_03_03_5\n",
      "completed write to table: tweetsprocessed2018_03_03_6\n",
      "completed write to table: tweetsprocessed2018_03_03_7\n",
      "completed write to table: tweetsprocessed2018_03_03_8\n",
      "completed write to table: tweetsprocessed2018_03_03_9\n",
      "completed write to table: tweetsprocessed2018_03_04_1\n",
      "completed write to table: tweetsprocessed2018_03_04_2\n",
      "completed write to table: tweetsprocessed2018_03_04_3\n",
      "completed write to table: tweetsprocessed2018_03_04_4\n",
      "completed write to table: tweetsprocessed2018_03_05_1\n",
      "completed write to table: tweetsprocessed2018_03_05_2\n",
      "completed write to table: tweetsprocessed2018_03_05_3\n",
      "completed write to table: tweetsprocessed2018_03_05_4\n",
      "completed write to table: tweetsprocessed2018_03_05_5\n",
      "completed write to table: tweetsprocessed2018_03_05_6\n",
      "completed write to table: tweetsprocessed2018_03_05_7\n",
      "completed write to table: tweetsprocessed2018_03_05_8\n",
      "completed write to table: tweetsprocessed2018_03_06_1\n",
      "completed write to table: tweetsprocessed2018_03_06_2\n",
      "completed write to table: tweetsprocessed2018_03_06_3\n",
      "completed write to table: tweetsprocessed2018_03_06_4\n",
      "completed write to table: tweetsprocessed2018_03_06_5\n",
      "completed write to table: tweetsprocessed2018_03_06_6\n",
      "completed write to table: tweetsprocessed2018_03_06_7\n",
      "completed write to table: tweetsprocessed2018_03_06_8\n",
      "completed write to table: tweetsprocessed2018_03_06_9\n",
      "completed write to table: tweetsprocessed2018_03_07_1\n",
      "completed write to table: tweetsprocessed2018_03_07_2\n",
      "completed write to table: tweetsprocessed2018_03_07_3\n",
      "completed write to table: tweetsprocessed2018_03_07_4\n",
      "completed write to table: tweetsprocessed2018_03_07_5\n",
      "completed write to table: tweetsprocessed2018_03_08_1\n",
      "completed write to table: tweetsprocessed2018_03_08_2\n",
      "completed write to table: tweetsprocessed2018_03_08_3\n",
      "completed write to table: tweetsprocessed2018_03_08_4\n",
      "completed write to table: tweetsprocessed2018_03_08_5\n",
      "completed write to table: tweetsprocessed2018_03_09_1\n",
      "completed write to table: tweetsprocessed2018_03_09_2\n",
      "completed write to table: tweetsprocessed2018_03_09_3\n",
      "completed write to table: tweetsprocessed2018_03_09_4\n",
      "completed write to table: tweetsprocessed2018_03_09_5\n",
      "completed write to table: tweetsprocessed2018_03_09_6\n",
      "completed write to table: tweetsprocessed2018_03_09_7\n",
      "completed write to table: tweetsprocessed2018_03_09_8\n",
      "completed write to table: tweetsprocessed2018_03_09_9\n",
      "CPU times: user 2min 45s, sys: 18.3 s, total: 3min 4s\n",
      "Wall time: 8min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# read in each tweet file and do basic cleanup and write to postgres table\n",
    "for afile in file_list:\n",
    "    tweet_df = pd.read_csv(afile, lineterminator='\\n')\n",
    "    tweet_df = tweet_df[['id', 'tokens']]\n",
    "    tweet_df['tokens'] = tweet_df['tokens'].astype('str') \n",
    "    tweet_df['tokens'] = tweet_df['tokens'].apply(lambda x: re.sub('\\s+',' ',x) )\n",
    "    tweet_table = afile.split('/')[-1].lower()\n",
    "    tweet_table = tweet_table.replace('-', '_')\n",
    "    tweet_table = tweet_table[:-4]\n",
    "    write_results_pg(tweet_df, tweet_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3dev",
   "language": "python",
   "name": "py3dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
